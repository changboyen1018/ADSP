# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfVAi654IglsZiznZBjExVmrtxRFn692
"""
##SECTION1##

!pip install torch torchvision
!pip install transformers

from transformers import ViTFeatureExtractor, ViTForImageClassification
import torch
import io
import requests
from PIL import Image

feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')


##SECTION2##

from PIL import Image
import requests
from io import BytesIO

# 從網路上載入一張圖片並命名為 images
url = "https://imgur.com/gallery/IATPuwF.jpg"  # 你可以改成你想要的圖片網址
response = requests.get(url,stream=True)
images = Image.open(io.BytesIO(response.content))

# Ensure the image is RGB
if images.mode != "RGB":
    images = images.convert("RGB")


inputs = feature_extractor(images, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits
predicted_class_idx = logits.argmax(-1).item()


##SECTION3##


from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

# 資料擴增
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
])

# 定義數據集
train_dataset = ImageFolder(root='path_to_your_training_data', transform=transform) #自己增加訓練數據集'path_to_your_training_data'
val_dataset = ImageFolder(root='path_to_your_validation_data', transform=transform) #自己增加驗證數據集'path_to_your_validation_data'

# 定義數據加載器
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)


##SECTION4## 
##FINAL##

from torch import nn, optim

# 定義損失函數和優化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 開始訓練
for epoch in range(num_epochs):
    for images, labels in train_dataloader:
        inputs = feature_extractor(images, return_tensors="pt")
        outputs = model(**inputs)
        loss = criterion(outputs.logits, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

